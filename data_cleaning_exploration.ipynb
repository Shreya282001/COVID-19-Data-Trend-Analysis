{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X951UmeHSHd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY23Enx0Sa4D",
        "outputId": "2cd912b6-0eb9-4117-8c2a-1dd016032462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the folder containing the CSV files in Google Drive\n",
        "folder_path = '/content/drive/MyDrive/csse_covid_19_daily_reports'  # Adjust this path as needed\n",
        "\n",
        "# Output file path (save in Google Drive)\n",
        "output_file_path = '/content/drive/MyDrive/combined_dataset.csv'\n",
        "\n",
        "# Get a list of all CSV files in the folder\n",
        "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
        "\n",
        "# Create an empty list to store DataFrames\n",
        "df_list = []\n",
        "\n",
        "# Read each CSV file and append to the list\n",
        "for file in csv_files:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    temp_df = pd.read_csv(file_path)\n",
        "    df_list.append(temp_df)\n",
        "\n",
        "# Concatenate all DataFrames in the list into one large DataFrame\n",
        "combined_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Save the combined DataFrame to a CSV file in Google Drive\n",
        "combined_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Combined dataset saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOkLxxy-VD5R",
        "outputId": "e7d422ec-4233-4be2-dd9a-49eb3e40885b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset saved to /content/drive/MyDrive/combined_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ViaLdbXUrl",
        "outputId": "9802af34-f307-4326-9e25-e7274e80263a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   FIPS Admin2 Province_State Country_Region          Last_Update       Lat  \\\n",
            "0   NaN    NaN            NaN    Afghanistan  2023-02-10 20:20:57  33.93911   \n",
            "1   NaN    NaN            NaN        Albania  2023-02-10 20:20:57  41.15330   \n",
            "2   NaN    NaN            NaN        Algeria  2023-02-10 20:20:57  28.03390   \n",
            "3   NaN    NaN            NaN        Andorra  2023-02-10 20:20:57  42.50630   \n",
            "4   NaN    NaN            NaN         Angola  2023-02-10 20:20:57 -11.20270   \n",
            "\n",
            "       Long_  Confirmed  Deaths  Recovered  ...  Combined_Key Incident_Rate  \\\n",
            "0  67.709953   208943.0  7896.0        NaN  ...   Afghanistan    536.737489   \n",
            "1  20.168300   334229.0  3596.0        NaN  ...       Albania  11614.045451   \n",
            "2   1.659600   271406.0  6881.0        NaN  ...       Algeria    618.927126   \n",
            "3   1.521800    47860.0   165.0        NaN  ...       Andorra  61942.664855   \n",
            "4  17.873900   105184.0  1931.0        NaN  ...        Angola    320.036336   \n",
            "\n",
            "   Case_Fatality_Ratio  Province/State Country/Region Last Update Latitude  \\\n",
            "0             3.779021             NaN            NaN         NaN      NaN   \n",
            "1             1.075909             NaN            NaN         NaN      NaN   \n",
            "2             2.535316             NaN            NaN         NaN      NaN   \n",
            "3             0.344756             NaN            NaN         NaN      NaN   \n",
            "4             1.835831             NaN            NaN         NaN      NaN   \n",
            "\n",
            "   Longitude  Incidence_Rate  Case-Fatality_Ratio  \n",
            "0        NaN             NaN                  NaN  \n",
            "1        NaN             NaN                  NaN  \n",
            "2        NaN             NaN                  NaN  \n",
            "3        NaN             NaN                  NaN  \n",
            "4        NaN             NaN                  NaN  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the total number of rows\n",
        "total_rows = combined_df.shape[0]\n",
        "print(f\"Total number of rows in the combined dataset: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAicsUqQXYLq",
        "outputId": "853d4dd7-06cb-4075-f740-8920dc9c0ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in the combined dataset: 4327543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the uploaded CSV file in Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/combined_dataset.csv'  # Update with the actual file name\n",
        "\n",
        "# Output file path (save the modified file in Google Drive)\n",
        "output_file_path = '/content/drive/MyDrive/modified_dataset.csv'  # Path for the modified file\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Remove the 'FIPS' and 'Admin2' columns if they exist\n",
        "df = df.drop(columns=['FIPS', 'Admin2'], errors='ignore')\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file in Google Drive\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Modified dataset saved to {output_file_path}\")\n",
        "\n",
        "# Display the first 5 rows of the modified dataset\n",
        "print(df.head())  # Shows the first 5 rows of the modified DataFrame\n",
        "\n",
        "# Display the total number of rows in the modified dataset\n",
        "total_rows = df.shape[0]\n",
        "print(f\"Total number of rows in the modified dataset: {total_rows}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bp3vSqMZU8d",
        "outputId": "dd56028e-454d-4a30-fdee-1d83463abe85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-bbdc5fd3da0c>:10: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified dataset saved to /content/drive/MyDrive/modified_dataset.csv\n",
            "  Province_State Country_Region          Last_Update       Lat      Long_  \\\n",
            "0            NaN    Afghanistan  2023-02-10 20:20:57  33.93911  67.709953   \n",
            "1            NaN        Albania  2023-02-10 20:20:57  41.15330  20.168300   \n",
            "2            NaN        Algeria  2023-02-10 20:20:57  28.03390   1.659600   \n",
            "3            NaN        Andorra  2023-02-10 20:20:57  42.50630   1.521800   \n",
            "4            NaN         Angola  2023-02-10 20:20:57 -11.20270  17.873900   \n",
            "\n",
            "   Confirmed  Deaths  Recovered  Active Combined_Key  Incident_Rate  \\\n",
            "0   208943.0  7896.0        NaN     NaN  Afghanistan     536.737489   \n",
            "1   334229.0  3596.0        NaN     NaN      Albania   11614.045451   \n",
            "2   271406.0  6881.0        NaN     NaN      Algeria     618.927126   \n",
            "3    47860.0   165.0        NaN     NaN      Andorra   61942.664855   \n",
            "4   105184.0  1931.0        NaN     NaN       Angola     320.036336   \n",
            "\n",
            "   Case_Fatality_Ratio Province/State Country/Region Last Update  Latitude  \\\n",
            "0             3.779021            NaN            NaN         NaN       NaN   \n",
            "1             1.075909            NaN            NaN         NaN       NaN   \n",
            "2             2.535316            NaN            NaN         NaN       NaN   \n",
            "3             0.344756            NaN            NaN         NaN       NaN   \n",
            "4             1.835831            NaN            NaN         NaN       NaN   \n",
            "\n",
            "   Longitude  Incidence_Rate  Case-Fatality_Ratio  \n",
            "0        NaN             NaN                  NaN  \n",
            "1        NaN             NaN                  NaN  \n",
            "2        NaN             NaN                  NaN  \n",
            "3        NaN             NaN                  NaN  \n",
            "4        NaN             NaN                  NaN  \n",
            "Total number of rows in the modified dataset: 4327543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your uploaded CSV file in Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/modified_dataset.csv'  # Update with the actual file name\n",
        "\n",
        "# Output file path for cleaned data\n",
        "output_file_path = '/content/drive/MyDrive/cleaned_dataset.csv'  # Path for the cleaned file\n",
        "\n",
        "# Step 1: Read the dataset\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Drop unnecessary columns (e.g., 'FIPS', 'Admin2')\n",
        "df = df.drop(columns=['FIPS', 'Admin2'], errors='ignore')\n",
        "\n",
        "# Step 3: Check for missing values\n",
        "missing_data = df.isnull().sum()  # Count of missing values in each column\n",
        "print(\"Missing Data:\")\n",
        "print(missing_data)\n",
        "\n",
        "# Handle missing values - Example: Drop rows with missing values in critical columns\n",
        "# You can adjust the strategy based on the column and the context of your data.\n",
        "df = df.dropna(subset=['Confirmed', 'Deaths', 'Recovered'], how='any')  # Drop rows where these columns are NaN\n",
        "\n",
        "# Alternatively, you can fill missing values (impute) for non-critical columns, if needed:\n",
        "# df['Column_Name'].fillna(df['Column_Name'].mean(), inplace=True)  # Impute with the mean (for numeric columns)\n",
        "\n",
        "# Step 4: Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Step 5: Convert data types\n",
        "# Convert the 'Last_Update' column to datetime format\n",
        "df['Last_Update'] = pd.to_datetime(df['Last_Update'], errors='coerce')\n",
        "\n",
        "# Step 6: Check and handle outliers (if applicable)\n",
        "# For example, you can visualize distributions or remove extreme values for numerical columns like 'Confirmed', 'Deaths', etc.\n",
        "# This step depends on the data and should be customized based on the dataset.\n",
        "\n",
        "# Step 7: Standardize any categorical data (e.g., string columns)\n",
        "df['Country_Region'] = df['Country_Region'].str.strip().str.title()  # Standardize country names (capitalization)\n",
        "\n",
        "# Step 8: Save the cleaned dataset\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned dataset saved to {output_file_path}\")\n",
        "\n",
        "# Optional: Display the first 5 rows of the cleaned dataset\n",
        "print(df.head())\n",
        "\n",
        "# Optional: Display total number of rows in the cleaned dataset\n",
        "total_rows = df.shape[0]\n",
        "print(f\"Total number of rows in the cleaned dataset: {total_rows}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-RDObZ7iOrl",
        "outputId": "42c64721-dc19-4181-f1b3-3f8b6d38cbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8b6cfdfb0578>:10: DtypeWarning: Columns (12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Data:\n",
            "Province_State          205488\n",
            "Country_Region            9797\n",
            "Last_Update               9797\n",
            "Lat                     104980\n",
            "Long_                   104980\n",
            "Confirmed                   28\n",
            "Deaths                     433\n",
            "Recovered              2852503\n",
            "Active                 2861916\n",
            "Combined_Key              9797\n",
            "Incident_Rate           965347\n",
            "Case_Fatality_Ratio     923759\n",
            "Province/State         4321456\n",
            "Country/Region         4317746\n",
            "Last Update            4317746\n",
            "Latitude               4322051\n",
            "Longitude              4322051\n",
            "Incidence_Rate         3681842\n",
            "Case-Fatality_Ratio    3678226\n",
            "dtype: int64\n",
            "Cleaned dataset saved to /content/drive/MyDrive/cleaned_dataset.csv\n",
            "     Province_State Country_Region         Last_Update       Lat      Long_  \\\n",
            "4016            NaN    Afghanistan 2021-02-13 05:22:12  33.93911  67.709953   \n",
            "4017            NaN        Albania 2021-02-13 05:22:12  41.15330  20.168300   \n",
            "4018            NaN        Algeria 2021-02-13 05:22:12  28.03390   1.659600   \n",
            "4019            NaN        Andorra 2021-02-13 05:22:12  42.50630   1.521800   \n",
            "4020            NaN         Angola 2021-02-13 05:22:12 -11.20270  17.873900   \n",
            "\n",
            "      Confirmed  Deaths  Recovered   Active Combined_Key  Incident_Rate  \\\n",
            "4016    55445.0  2424.0    48390.0   4631.0  Afghanistan     142.428366   \n",
            "4017    90835.0  1531.0    55243.0  34061.0      Albania    3156.404198   \n",
            "4018   110303.0  2932.0    75628.0  31743.0      Algeria     251.540197   \n",
            "4019    10427.0   106.0     9833.0    488.0      Andorra   13495.114217   \n",
            "4020    20294.0   490.0    18786.0   1018.0       Angola      61.747199   \n",
            "\n",
            "      Case_Fatality_Ratio Province/State Country/Region Last Update  Latitude  \\\n",
            "4016             4.371900            NaN            NaN         NaN       NaN   \n",
            "4017             1.685474            NaN            NaN         NaN       NaN   \n",
            "4018             2.658133            NaN            NaN         NaN       NaN   \n",
            "4019             1.016592            NaN            NaN         NaN       NaN   \n",
            "4020             2.414507            NaN            NaN         NaN       NaN   \n",
            "\n",
            "      Longitude  Incidence_Rate  Case-Fatality_Ratio  \n",
            "4016        NaN             NaN                  NaN  \n",
            "4017        NaN             NaN                  NaN  \n",
            "4018        NaN             NaN                  NaN  \n",
            "4019        NaN             NaN                  NaN  \n",
            "4020        NaN             NaN                  NaN  \n",
            "Total number of rows in the cleaned dataset: 1453473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Lat'].fillna(df['Lat'].mean(), inplace=True)  # Fill missing latitude values with the mean\n",
        "df['Long_'].fillna(df['Long_'].mean(), inplace=True)  # Fill missing longitude values with the mean\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNarkI1dnlZH",
        "outputId": "41ca7bbe-bce4-480c-d89d-92d1ade748cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1a5c2811a665>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Lat'].fillna(df['Lat'].mean(), inplace=True)  # Fill missing latitude values with the mean\n",
            "<ipython-input-3-1a5c2811a665>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Long_'].fillna(df['Long_'].mean(), inplace=True)  # Fill missing longitude values with the mean\n"
          ]
        }
      ]
    }
  ]
}